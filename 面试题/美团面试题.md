# HashMap1.8与1.7区别？ConcurrentHashMap实现原理 ？

1.7：HashMap数组+链表实现，头插法，扩容会有死循环的问题。1.8：HashMap数组+链表+红黑树，尾插法解决扩容死循环问题

1.7：ConcurrentHashMap使用分段锁机制   1.8：ConcurrentHashMap实现CAS+Syn锁机制



# jvm类加载器,自定义类加载器,双亲委派机制,优缺点,tomcat类加载机制?

后续补充吧



# tomcat热部署，怎么做到的热加载？

后续补充吧



# cms收集器过程，g1收集器原理，怎么实现可预测停顿的，region的大小结构？

cms收集器过程：

1. 初始标记：标记GC Roots关联的对象，注意：仅仅是标记关联的对象，不会做可达性分析，所以速度是非常快的，此操作会STW
2. 并发标记：通过初始标记出的关联对象往下做引用链搜索，此操作与用户线程并发执行
3. 重新标记：因为并发标记是与用户线程并发执行的，所以在标记期间用户线程是可能会修改或新增某些对象间的引用关系的，所以需要重新标记一次，此操作会STW
4. 并发清除：并发清除掉垃圾对象，由于不需要移动内存，所以可以与用户线程一起执行

此外，如果再GC期间产生的新对象大小>=预留的内存大小，则会STW所有用户线程，启用Serial Old回收



G1：将堆分为N个region，每个region可被分为eden和old区，g1根据不同的region区选择不同的策略回收，此外g1还有个humgongs区来存放大对象（超过region一半大小的对象就是大对象），超过整个region的大对象会被分配到N个连续的humgongs。

所以，G1每次会优先回收内存占用多的region，且不会对整块堆内存做回收，提高了性能

region的大小可通过：XX:G1HeapRegionSize配置，最小1M，最大32M，且大小应为2的幂次方。数量：2048个



G1可预测停顿：因为G1是回收部分region，而回收的大小取决于用户配置的STW暂停时间，配置的时间短就少回收点，反之就多回收点，相比其他GC，因为其他GC是回收整块内存，所以回收时间不可控，而G1相对来说是可控的



G1的回收步骤：

1. 初始标记：标记GC Roots关联的对象，注意：仅仅是标记关联的对象，不会做可达性分析，所以速度是非常快的，此操作会STW
2. 并发标记：通过初始标记的对象做可达性分析，标记可回收的对象，此操作与用户线程并发执行
3. 最终标记：并发标记结束后，对SATB记录做可达性分析，标记可回收对象，此操作会STW
4. 筛选回收：对每个Region的最大收益进行排序，根据用户设定的停顿时间来指定回收计划，构成回收集，然后把存活的Region内的对象复制到空闲的Region中，最后回收掉垃圾对象。此操作会STW，多线程回收





# volatile的原理？synchronized和重入锁实现原理以及区别？

volatile：保证可见性，禁止指令重排，不保证原子性，通过JMM实现

synchronized：JVM的锁，无论是否异常都会自动释放锁，有锁升级，锁粗化，锁消除等优化，非公平，可重入，不可中断

Lock：jdk的锁，AQS实现，可重入，支持公平/非公平。更灵活，支持condition，需手动释放锁，可通过interrupt()中断





# redis字符串实现，sds和c区别？

| SDS                                      | C                                    |
| :--------------------------------------- | ------------------------------------ |
| 获取字符串长度时间复杂度为O(1)           | 获取字符串时间复杂度为O(n)           |
| API是安全的，不会造成缓存区溢出          | API不安全，可能会造成缓冲区溢出      |
| 修改字符串长度N次最多需要执行N次内存分配 | 修改字符串长度N次必需执行N次内存分配 |
| 能保存文本及二进制                       | 只能保存文本                         |
| 可以使用所有<string.h>库中的函数         | 可以使用一部分<string.h>库中的函数   |



# redis集群，为什么是16384个slot？选举过程，会有脑裂问题么，raft算法，优缺点？

为什么是16384个slot：

 	1. redis集群中master节点数量不应该超过1000个（redis作者建议），因为节点越多心跳包带的数据越大，如果节点超过1000个会导致网络拥堵，那么，对于节点数在1000以内的redis cluster集群，16384个槽位够用了
 	2. 槽位越小，节点越少压缩率更高，因为master节点对应的槽信息是通过bitmap保存的，在传输过程中会对bitmap压缩，如果bitmap填充率slots/节点数 很高的话，bitmap压缩率就很低

没有脑裂问题，因为如果master挂掉，选举出新的master后，旧的master又恢复了会自动降为salve

raft：

​	





